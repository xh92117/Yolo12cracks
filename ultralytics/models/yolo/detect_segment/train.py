# Ultralytics YOLO ğŸš€, AGPL-3.0 license

from copy import copy

import torch

from ultralytics.data import build_dataloader, build_yolo_dataset
from ultralytics.engine.trainer import BaseTrainer
from ultralytics.models.yolo.detect.train import DetectionTrainer
from ultralytics.models.yolo.segment.train import SegmentationTrainer
from ultralytics.nn.tasks import attempt_load_one_weight
from ultralytics.utils import RANK, colorstr

from .network import DetectSegmentationModel, DetectSegmentLoss


class DetectSegmentTrainer(BaseTrainer):
    """
    è”åˆè®­ç»ƒç±»ï¼Œç»“åˆç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ä»»åŠ¡
    
    ç»§æ‰¿è‡ªBaseTrainerï¼Œä¸“é—¨å¤„ç†åŒæ—¶è¿›è¡Œç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²çš„è®­ç»ƒã€‚
    """

    def __init__(self, cfg=None, overrides=None, _callbacks=None):
        """
        åˆå§‹åŒ–è”åˆè®­ç»ƒå™¨
        
        Args:
            cfg (str, optional): é…ç½®æ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶å
            overrides (dict, optional): è¦†ç›–é»˜è®¤é…ç½®çš„å‚æ•°
            _callbacks (list, optional): å›è°ƒå‡½æ•°åˆ—è¡¨
        """
        # è®¾ç½®é»˜è®¤ä»»åŠ¡ä¸ºdetect_segment
        if overrides is None:
            overrides = {}
        overrides["task"] = "detect_segment"
        
        # åˆå§‹åŒ–åŸºç±»
        super().__init__(cfg, overrides, _callbacks)
        
        # ç¡®ä¿æ•°æ®é›†é…ç½®æ­£ç¡®
        if hasattr(self.args, "data"):
            self.data = self.args.data
        self.validator = None
        
        # è‡ªå®šä¹‰æ•°æ®åŠ è½½
        self.train_loader = self.get_dataloader(self.trainset, "train", rank=RANK)
        
        # åˆ›å»ºæ ¸å¿ƒæ¨¡å‹
        self.model = self.get_model()
        self.optimizer = self.build_optimizer()
        self.scheduler = self.build_lr_scheduler()
        self.loss = DetectSegmentLoss(self.model)
        
        self.args.model = self.model
        self.args.lr0 = self.args.lr0 * self.batch_size / 16

        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        if not self.resume:
            self.load_pretrained_weights()
        
        self.best_fitness = 0.0
        self.best_epoch = -1
        
    def get_model(self):
        """
        åŠ è½½æˆ–åˆ›å»ºæ¨¡å‹
        
        Returns:
            DetectSegmentationModel: è”åˆæ£€æµ‹åˆ†å‰²æ¨¡å‹
        """
        model = DetectSegmentationModel(cfg=self.args.model or "yolov12_detect_segment.yaml", nc=self.args.nc)
        
        return model
    
    def preprocess_batch(self, batch):
        """
        é¢„å¤„ç†æ‰¹æ¬¡æ•°æ®
        
        Args:
            batch (dict): åŒ…å«å›¾åƒå’Œæ ‡ç­¾çš„æ‰¹æ¬¡æ•°æ®
            
        Returns:
            dict: é¢„å¤„ç†åçš„æ‰¹æ¬¡æ•°æ®
        """
        # ç¡®ä¿æ¯ä¸ªæ ·æœ¬åŒæ—¶æœ‰è¾¹ç•Œæ¡†å’Œå®ä¾‹æ©ç 
        batch["img"] = batch["img"].to(self.device, non_blocking=True)
        batch["cls"] = batch["cls"].to(self.device)
        batch["bboxes"] = batch["bboxes"].to(self.device)
        
        # å¤„ç†åˆ†å‰²æ©ç 
        if "masks" in batch:
            batch["masks"] = batch["masks"].to(self.device).float()
        else:
            # å¦‚æœæ²¡æœ‰æ©ç ï¼Œä½¿ç”¨è¾¹ç•Œæ¡†ç”Ÿæˆç²—ç•¥æ©ç ï¼ˆè®­ç»ƒé˜¶æ®µï¼‰
            if self.args.overlap_mask and "batch_idx" in batch:
                h, w = batch["img"].shape[2:]
                masks = torch.zeros((batch["bboxes"].shape[0], h, w), device=self.device)
                for i, box in enumerate(batch["bboxes"]):
                    x1, y1, x2, y2 = map(int, box[:4])
                    masks[i, y1:y2, x1:x2] = 1
                batch["masks"] = masks
        
        return batch
    
    def _do_train_epoch(self, epoch):
        """
        æ‰§è¡Œä¸€ä¸ªè®­ç»ƒepoch
        
        Args:
            epoch (int): å½“å‰epochç¼–å·
            
        Returns:
            dict: æŸå¤±å’ŒæŒ‡æ ‡å­—å…¸
        """
        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        self.model.train()
        self.model.requires_grad_(True)
        
        # è®­ç»ƒå¾ªç¯
        pbar = self.progress_bar(self.train_loader, description=self.epoch_progress_string.format(epoch))
        self.lr_scheduler.last_epoch = epoch - 1  # do not move
        
        for batch_idx, batch in enumerate(pbar):
            # é¢„å¤„ç†
            ni = batch_idx + self.epoch_size * epoch
            batch = self.preprocess_batch(batch)
            
            # å‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®—
            self.optimizer.zero_grad()
            preds = self.model(batch["img"])
            loss, loss_items = self.loss(preds, batch)
            
            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.lr_scheduler.step_after_batch(ni)
            
            # è®°å½•æŸå¤±
            if RANK == 0:
                self.loss_items.update({k: v for k, v in loss_items.items()})
                self.log_train_batch(batch_idx, ni, {**{"lr": self.optimizer.param_groups[0]["lr"]}, **loss_items})
                
                # æ›´æ–°è¿›åº¦æ¡æè¿°
                memory = f"{torch.cuda.memory_reserved() / 1E9:.3g}G"  # nvidia only
                base_str = f"Epoch {epoch}/{self.epochs - 1 if self.epochs > 1 else 1}"
                pbar.set_description(f"{base_str}: {memory}")
                
        return {**{"lr": self.optimizer.param_groups[0]["lr"]}, **self.loss_items.result()}
    
    def get_validator(self):
        """
        è·å–éªŒè¯å™¨
        
        Returns:
            DetectSegmentValidator: è”åˆæ£€æµ‹åˆ†å‰²éªŒè¯å™¨
        """
        if self.validator is None:
            self.validator = DetectSegmentValidator(
                dataloader=self.get_dataloader(self.testset, "val", rank=RANK),
                save_dir=self.save_dir,
                args=copy(self.args),
            )
        return self.validator
    
    def load_pretrained_weights(self):
        """
        åŠ è½½é¢„è®­ç»ƒæƒé‡
        
        å¯ä»¥åŠ è½½æ£€æµ‹å’Œåˆ†å‰²é¢„è®­ç»ƒæƒé‡å¹¶åˆå¹¶
        """
        if self.args.pretrained.lower() == "false":
            return
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è”åˆé¢„è®­ç»ƒæƒé‡
        try:
            # å°è¯•ç›´æ¥åŠ è½½è”åˆæ¨¡å‹æƒé‡
            weights = attempt_load_one_weight(self.args.pretrained)
            ckpt = weights.float().state_dict()
            self.model.load_state_dict(ckpt, strict=False)
            print(f"æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡: {colorstr('bold', 'green', self.args.pretrained)}")
        except Exception:
            # å°è¯•å•ç‹¬åŠ è½½æ£€æµ‹å’Œåˆ†å‰²æƒé‡
            print(f"æ— æ³•ç›´æ¥åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œå°è¯•åˆ†åˆ«åŠ è½½æ£€æµ‹å’Œåˆ†å‰²æƒé‡...")
            
            # åŠ è½½æ£€æµ‹æƒé‡
            try:
                detect_weights = attempt_load_one_weight("yolov12n.pt")
                detect_ckpt = detect_weights.float().state_dict()
                
                # ä»…åŠ è½½éª¨å¹²ç½‘ç»œå’Œæ£€æµ‹å¤´éƒ¨åˆ†
                model_state_dict = self.model.state_dict()
                for k, v in detect_ckpt.items():
                    if k in model_state_dict and (not k.startswith("segment_head")):
                        model_state_dict[k] = v
                
                self.model.load_state_dict(model_state_dict, strict=False)
                print(f"æˆåŠŸåŠ è½½æ£€æµ‹é¢„è®­ç»ƒæƒé‡")
            except Exception as e:
                print(f"åŠ è½½æ£€æµ‹æƒé‡å¤±è´¥: {e}")
            
            # åŠ è½½åˆ†å‰²æƒé‡
            try:
                segment_weights = attempt_load_one_weight("yolov8n-seg.pt")
                segment_ckpt = segment_weights.float().state_dict()
                
                # å¯¹åˆ†å‰²å¤´éƒ¨åˆ†é‡å‘½åé”®å¹¶åŠ è½½
                model_state_dict = self.model.state_dict()
                for k, v in segment_ckpt.items():
                    if k.startswith("model.28"):  # åˆ†å‰²å¤´
                        new_k = k.replace("model.28", "segment_head.0")
                        if new_k in model_state_dict:
                            model_state_dict[new_k] = v
                
                self.model.load_state_dict(model_state_dict, strict=False)
                print(f"æˆåŠŸåŠ è½½åˆ†å‰²é¢„è®­ç»ƒæƒé‡")
            except Exception as e:
                print(f"åŠ è½½åˆ†å‰²æƒé‡å¤±è´¥: {e}")


class DetectSegmentValidator:
    """
    è”åˆæ£€æµ‹åˆ†å‰²éªŒè¯å™¨
    
    ç”¨äºéªŒè¯æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡çš„æ€§èƒ½ï¼Œè®¡ç®—ç»¼åˆæŒ‡æ ‡ã€‚
    """
    
    def __init__(self, dataloader=None, save_dir=None, args=None, _callbacks=None):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            dataloader: éªŒè¯æ•°æ®åŠ è½½å™¨
            save_dir: ä¿å­˜ç»“æœçš„ç›®å½•
            args: å‚æ•°
            _callbacks: å›è°ƒå‡½æ•°åˆ—è¡¨
        """
        self.args = args or {}
        
        # åˆ›å»ºæ£€æµ‹å’Œåˆ†å‰²éªŒè¯å™¨
        from ultralytics.models.yolo.detect.val import DetectionValidator
        from ultralytics.models.yolo.segment.val import SegmentationValidator
        
        self.det_validator = DetectionValidator(dataloader, save_dir, args, _callbacks)
        self.seg_validator = SegmentationValidator(dataloader, save_dir, args, _callbacks)
        
    def __call__(self, trainer=None, model=None):
        """éªŒè¯æ¨¡å‹æ€§èƒ½"""
        return self.validate(trainer, model)
    
    def validate(self, trainer=None, model=None):
        """
        æ‰§è¡ŒéªŒè¯
        
        Args:
            trainer: è®­ç»ƒå™¨å®ä¾‹
            model: æ¨¡å‹å®ä¾‹
            
        Returns:
            dict: éªŒè¯æŒ‡æ ‡
        """
        model = model or (trainer.model if trainer else None)
        metrics = {}
        
        # æ‰§è¡Œæ£€æµ‹éªŒè¯
        det_metrics = self.det_validator(trainer, model)
        
        # æ‰§è¡Œåˆ†å‰²éªŒè¯
        seg_metrics = self.seg_validator(trainer, model)
        
        # åˆå¹¶æŒ‡æ ‡
        for k, v in det_metrics.items():
            metrics[f"detect_{k}"] = v
        
        for k, v in seg_metrics.items():
            metrics[f"segment_{k}"] = v
        
        # è®¡ç®—ç»„åˆæŒ‡æ ‡ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´æƒé‡ï¼‰
        box_map = det_metrics["metrics/mAP50-95(B)"]
        mask_map = seg_metrics["metrics/mAP50-95(M)"]
        metrics["fitness"] = 0.6 * box_map + 0.4 * mask_map  # ç»„åˆæŒ‡æ ‡
        
        return metrics


class DetectSegmentPredictor:
    """
    è”åˆæ£€æµ‹åˆ†å‰²é¢„æµ‹å™¨
    
    ç”¨äºç”Ÿæˆæ£€æµ‹å’Œåˆ†å‰²ç»“æœã€‚
    """
    
    def __init__(self, cfg=None, overrides=None, _callbacks=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            cfg: é…ç½®æ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶å
            overrides: è¦†ç›–é»˜è®¤é…ç½®çš„å‚æ•°
            _callbacks: å›è°ƒå‡½æ•°åˆ—è¡¨
        """
        from ultralytics.models.yolo.detect.predict import DetectionPredictor
        from ultralytics.models.yolo.segment.predict import SegmentationPredictor
        
        # åˆ›å»ºæ£€æµ‹å’Œåˆ†å‰²é¢„æµ‹å™¨
        overrides = overrides or {}
        self.det_predictor = DetectionPredictor(cfg, overrides, _callbacks)
        self.seg_predictor = SegmentationPredictor(cfg, overrides, _callbacks)
        
        # å­˜å‚¨å‚æ•°
        self.overrides = overrides
        self.args = self.det_predictor.args
    
    def predict(self, source=None, model=None, verbose=False, stream=False):
        """
        ç”Ÿæˆé¢„æµ‹ç»“æœ
        
        Args:
            source: è¾“å…¥æº
            model: æ¨¡å‹å®ä¾‹
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            stream: æ˜¯å¦æµå¼å¤„ç†
            
        Returns:
            list: é¢„æµ‹ç»“æœ
        """
        # æ‰§è¡Œæ£€æµ‹é¢„æµ‹
        det_results = self.det_predictor.predict(source, model, verbose, stream)
        
        # æ‰§è¡Œåˆ†å‰²é¢„æµ‹
        seg_results = self.seg_predictor.predict(source, model, verbose, stream)
        
        # åˆå¹¶ç»“æœ
        results = []
        for det_res, seg_res in zip(det_results, seg_results):
            # åˆ›å»ºåˆå¹¶ç»“æœ
            combined_res = copy(det_res)
            combined_res.masks = seg_res.masks  # æ·»åŠ åˆ†å‰²æ©ç 
            results.append(combined_res)
        
        return results 