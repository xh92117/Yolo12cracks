# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import torch
import torch.nn as nn

from ultralytics.nn.tasks import DetectionModel
from ultralytics.models.yolo.detect.train import Loss as DetectionLoss
from ultralytics.models.yolo.segment.train import Loss as SegmentationLoss
from ultralytics.nn.modules.block import A2C2f, C3k2
from ultralytics.nn.modules.head import Detect, Segment
from ultralytics.nn.modules.attention import MultiScaleAttentionEnhancement, AdaptiveScaleHead
from ultralytics.utils import DEFAULT_CFG
from ultralytics.utils.loss import FocalLoss
from ultralytics.utils.tal import TaskAlignedAssigner


class DetectSegmentationModel(DetectionModel):
    """YOLOv12æ¨¡å‹ï¼ŒåŒæ—¶å…·æœ‰ç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²èƒ½åŠ›
    
    è¿™ä¸ªæ¨¡å‹æ‰©å±•äº†æ ‡å‡†YOLOv12æ£€æµ‹æ¨¡å‹ï¼Œæ·»åŠ äº†åˆ†å‰²å¤´ï¼Œå¯åŒæ—¶è¾“å‡ºç›®æ ‡æ£€æµ‹è¾¹ç•Œæ¡†å’Œå®ä¾‹åˆ†å‰²æ©ç ã€‚
    ç‰¹åˆ«é€‚åˆè£‚ç¼æ£€æµ‹ï¼Œèƒ½åŒæ—¶è·å¾—è£‚ç¼ä½ç½®å’Œç²¾ç¡®å½¢çŠ¶ã€‚
    
    æ–°å¢åŠŸèƒ½:
    - å¤šå°ºåº¦æ³¨æ„åŠ›å¢å¼º(MSAE)ï¼Œè§£å†³æ ‡æ³¨æ¡†å°ºå¯¸å·®å¼‚è¿‡å¤§çš„é—®é¢˜
    - è‡ªé€‚åº”æ£€æµ‹å¤´ï¼Œé’ˆå¯¹ä¸åŒå°ºå¯¸çš„è£‚ç¼åŠ¨æ€è°ƒæ•´æ£€æµ‹ç­–ç•¥
    """
    
    def __init__(self, cfg='yolov12_detect_segment.yaml', ch=3, nc=None, verbose=True):
        """
        åˆå§‹åŒ–DetectSegmentationModel
        
        Args:
            cfg (str | dict): æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„æˆ–é…ç½®å­—å…¸
            ch (int): è¾“å…¥é€šé“æ•°
            nc (int, optional): ç±»åˆ«æ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
            verbose (bool): æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        super().__init__(cfg, ch, nc, verbose)  # ç»§æ‰¿DetectionModelåˆå§‹åŒ–
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šå°ºåº¦æ³¨æ„åŠ›å¢å¼ºæ¨¡å—
        self.has_msae = False
        if 'msae' in self.yaml:
            self.msae = self._build_msae()
            self.has_msae = True
        
        # åˆ†ç¦»å¤´éƒ¨æ¨¡å—
        is_crack_detection = cfg.endswith('yolov12_crack_detection.yaml')
        
        if is_crack_detection and self.has_msae:
            # ä½¿ç”¨è‡ªé€‚åº”æ£€æµ‹å¤´
            self.detect_head = self._build_adaptive_head('detect_head')
            self.segment_head = self._build_head('segment_head')
        else:
            # ä½¿ç”¨å¸¸è§„æ£€æµ‹å’Œåˆ†å‰²å¤´
            self.detect_head = self._build_head('detect_head')
            self.segment_head = self._build_head('segment_head')
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
        if verbose:
            self._info()

    def _build_msae(self):
        """æ„å»ºå¤šå°ºåº¦æ³¨æ„åŠ›å¢å¼ºæ¨¡å—"""
        m = nn.Sequential(*(self._build_block(x) for x in self.yaml['msae']))
        return m

    def _build_adaptive_head(self, head_name):
        """æ„å»ºé’ˆå¯¹è£‚ç¼æ£€æµ‹ç‰¹åˆ«ä¼˜åŒ–çš„è‡ªé€‚åº”æ£€æµ‹å¤´"""
        m = nn.Sequential(*(self._build_block(x) for x in self.yaml[head_name]))
        return m

    def _build_head(self, head_name):
        """
        æ„å»ºæ£€æµ‹å¤´æˆ–åˆ†å‰²å¤´
        
        Args:
            head_name (str): å¤´éƒ¨åç§°ï¼Œ'detect_head'æˆ–'segment_head'
            
        Returns:
            nn.Module: æ„å»ºçš„å¤´éƒ¨æ¨¡å—
        """
        if head_name == 'detect_head':
            m = nn.Sequential(*(self._build_block(x) for x in self.yaml[head_name]))
            if hasattr(m[-1], 'bias') and isinstance(m[-1].bias, torch.Tensor):
                # ä½¿ç”¨custom prioråˆå§‹åŒ–æ£€æµ‹å¤´
                m[-1].bias.data[:] = 1.0  # åˆå§‹åŒ–obj confidence
            return m
        elif head_name == 'segment_head':
            m = nn.Sequential(*(self._build_block(x) for x in self.yaml[head_name]))
            return m
        else:
            raise ValueError(f"æœªçŸ¥çš„å¤´éƒ¨ç±»å‹: {head_name}")

    def _build_block(self, layer_cfg):
        """
        æ„å»ºç½‘ç»œå—
        
        Args:
            layer_cfg (list): å±‚é…ç½®
            
        Returns:
            nn.Module: æ„å»ºçš„ç½‘ç»œå—
        """
        from_layer, num_modules, module_name, args = layer_cfg
        
        # ç‰¹æ®Šæ¨¡å—å¤„ç†
        special_modules = ['Detect', 'Segment', 'MultiScaleAttentionEnhancement', 'AdaptiveScaleHead']
        
        if isinstance(from_layer, list) and module_name in special_modules:
            # è·å–è¾“å…¥ç‰¹å¾å±‚
            from_layers = [self.save[x] if x < 0 else x for x in from_layer]
            
            if module_name == 'Detect':
                return Detect(nc=self.nc, ch=self.ch, args=self.args)
            elif module_name == 'Segment':
                return Segment(nc=self.nc, nm=args[1], npr=args[2], ch=self.ch, args=self.args)
            elif module_name == 'MultiScaleAttentionEnhancement':
                # å¤„ç†å¤šå°ºåº¦æ³¨æ„åŠ›å¢å¼ºæ¨¡å—
                from ultralytics.nn.modules.attention import MultiScaleAttentionEnhancement
                return MultiScaleAttentionEnhancement(args[0])
            elif module_name == 'AdaptiveScaleHead':
                # è‡ªé€‚åº”å°ºåº¦æ£€æµ‹å¤´
                from ultralytics.nn.modules.attention import AdaptiveScaleHead
                return AdaptiveScaleHead(args[0], nc=args[1])
        else:
            # ä½¿ç”¨åŸç”Ÿçš„æ„å»ºå—å®ç°
            return super()._build_block(layer_cfg)

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x (torch.Tensor): è¾“å…¥å›¾åƒ
            
        Returns:
            tuple: æ£€æµ‹å’Œåˆ†å‰²ç»“æœ
        """
        # è·å–éª¨å¹²ç½‘ç»œå’Œé¢ˆéƒ¨ç‰¹å¾
        y = []  # å­˜å‚¨ä¸­é—´ç‰¹å¾å›¾
        for m in self.model:
            if m.f != -1:  # å¦‚æœä¸æ˜¯ä½¿ç”¨ä¸Šä¸€å±‚ä½œä¸ºè¾“å…¥
                x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # ä»æ—©æœŸå±‚è·å–ç‰¹å¾
            x = m(x)  # å‰å‘ä¼ æ’­
            y.append(x if m.i in self.save else None)  # ä¿å­˜è¾“å‡º
        
        # å‡†å¤‡æ£€æµ‹å’Œåˆ†å‰²çš„ç‰¹å¾
        p3, p4, p5 = y[14], y[17], y[20]  # æå–P3, P4, P5ç‰¹å¾
        features = [p3, p4, p5]
        
        # åº”ç”¨å¤šå°ºåº¦æ³¨æ„åŠ›å¢å¼ºï¼ˆå¦‚æœæœ‰ï¼‰
        if self.has_msae:
            enhanced_features = self.msae([features])
            # åˆ†åˆ«è·å–æ£€æµ‹å’Œåˆ†å‰²ç»“æœï¼ˆä½¿ç”¨å¢å¼ºåçš„ç‰¹å¾ï¼‰
            detect_out = self.detect_head(enhanced_features)
            segment_out = self.segment_head(enhanced_features)
        else:
            # ç›´æ¥ä½¿ç”¨åŸå§‹ç‰¹å¾
            detect_out = self.detect_head(features)
            segment_out = self.segment_head(features)
        
        return detect_out, segment_out


class DetectSegmentLoss(nn.Module):
    """
    æ£€æµ‹åˆ†å‰²è”åˆæŸå¤±å‡½æ•°
    
    è¯¥ç±»ç»“åˆäº†ç›®æ ‡æ£€æµ‹æŸå¤±å’Œå®ä¾‹åˆ†å‰²æŸå¤±ï¼Œç”¨äºè”åˆè®­ç»ƒã€‚
    å¯ä»¥é€šè¿‡è¶…å‚æ•°è°ƒæ•´ä¸¤ä¸ªä»»åŠ¡çš„æƒé‡ã€‚
    
    æ”¯æŒé’ˆå¯¹ä¸åŒå°ºå¯¸ç›®æ ‡çš„è‡ªé€‚åº”æŸå¤±è°ƒæ•´ã€‚
    """
    
    def __init__(self, model):
        """
        åˆå§‹åŒ–è”åˆæŸå¤±å‡½æ•°
        
        Args:
            model (DetectSegmentationModel): ç›®æ ‡æ£€æµ‹åˆ†å‰²æ¨¡å‹
        """
        super().__init__()
        
        self.det_loss = DetectionLoss(model)
        self.seg_loss = SegmentationLoss(model)
        
        # è·å–æƒé‡é…ç½®
        loss_weights = getattr(model.args, 'loss_weights', None)
        if loss_weights is None:
            # é»˜è®¤æƒé‡
            self.box_weight = 1.0  # æ£€æµ‹æƒé‡
            self.mask_weight = 1.0  # åˆ†å‰²æƒé‡
        else:
            # ä»é…ç½®åŠ è½½æƒé‡
            self.box_weight = loss_weights.get('box', 1.0)
            self.mask_weight = loss_weights.get('mask', 1.0)
            
        # å°ºå¯¸è‡ªé€‚åº”æŸå¤±å¢å¼º
        self.size_aware_loss = model.yaml.get('size_aware_loss', True)
    
    def __call__(self, preds, batch):
        """
        è®¡ç®—è”åˆæŸå¤±
        
        Args:
            preds (tuple): æ¨¡å‹é¢„æµ‹ï¼Œ(detection_results, segmentation_results)
            batch (dict): åŒ…å«å›¾åƒå’Œæ ‡æ³¨çš„å­—å…¸
            
        Returns:
            tuple: (æ€»æŸå¤±, å„ç»„ä»¶æŸå¤±å­—å…¸)
        """
        # åˆ†ç¦»æ£€æµ‹å’Œåˆ†å‰²é¢„æµ‹
        det_preds, seg_preds = preds
        
        # è®¡ç®—æ£€æµ‹æŸå¤±
        det_loss, det_components = self.det_loss(det_preds, batch)
        
        # è®¡ç®—åˆ†å‰²æŸå¤±
        seg_loss, seg_components = self.seg_loss(seg_preds, batch)
        
        # å¦‚æœå¯ç”¨å°ºå¯¸æ„ŸçŸ¥æŸå¤±
        if self.size_aware_loss and 'bboxes' in batch:
            # è®¡ç®—ç›®æ ‡æ¡†çš„é¢ç§¯
            boxes = batch['bboxes']
            areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
            
            # æ ¹æ®é¢ç§¯åˆ’åˆ†å°ºå¯¸ç±»åˆ«
            small_box = areas < 32*32  # å°ç›®æ ‡ (å°äº32x32)
            medium_box = (areas >= 32*32) & (areas < 96*96)  # ä¸­ç­‰ç›®æ ‡
            large_box = areas >= 96*96  # å¤§ç›®æ ‡
            
            # é’ˆå¯¹å°ç›®æ ‡å¢åŠ æƒé‡ï¼ˆè§£å†³æ ‡æ³¨æ¡†å°ºå¯¸å·®å¼‚è¿‡å¤§é—®é¢˜ï¼‰
            small_weight = 1.5  # å°ç›®æ ‡æƒé‡å¢å¼º
            medium_weight = 1.0  # ä¸­ç­‰ç›®æ ‡æ ‡å‡†æƒé‡
            large_weight = 0.8  # å¤§ç›®æ ‡æƒé‡ç•¥å¾®é™ä½
            
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æƒé‡
            weights = torch.ones_like(areas)
            weights[small_box] = small_weight
            weights[medium_box] = medium_weight
            weights[large_box] = large_weight
            
            # åº”ç”¨æƒé‡åˆ°æ£€æµ‹æŸå¤±
            # è¿™åªæ˜¯ä¸€ä¸ªæ¦‚å¿µç¤ºèŒƒï¼Œå®é™…ä¸Šéœ€è¦å¯¹æŸå¤±å‡½æ•°è¿›è¡Œä¿®æ”¹
            # è¿™é‡Œå‡è®¾det_componentsä¸­æœ‰ä¸€ä¸ªitem_lossè¡¨ç¤ºæ¯ä¸ªç›®æ ‡çš„æŸå¤±
            if 'item_loss' in det_components:
                weighted_loss = det_components['item_loss'] * weights.to(det_components['item_loss'].device)
                det_loss = weighted_loss.sum() / max(1, weights.sum())
        
        # è®¡ç®—åŠ æƒæ€»æŸå¤±
        loss = self.box_weight * det_loss + self.mask_weight * seg_loss
        
        # åˆå¹¶æŸå¤±ç»„ä»¶
        components = {**det_components, **{f'seg_{k}': v for k, v in seg_components.items()}}
        components['box_weight'] = self.box_weight  # æ·»åŠ æƒé‡ä¿¡æ¯
        components['mask_weight'] = self.mask_weight
        
        return loss, components 